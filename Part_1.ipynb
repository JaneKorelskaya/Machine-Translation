{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eulvfJWl7ueY"
   },
   "source": [
    "# Part 1: Bilingual dictionary induction and unsupervised embedding-based MT\n",
    "*Note: this homework is based on materials from yandexdataschool [NLP course](https://github.com/yandexdataschool/nlp_course/). Feel free to check this awesome course if you wish to dig deeper.*\n",
    "\n",
    "*Refined by [Nikolay Karpachev](https://www.linkedin.com/in/nikolay-karpachev-b0146a104/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fV4rIjxa7uei"
   },
   "source": [
    "**In this homework** **<font color='red'>YOU</font>** will make machine translation system without using parallel corpora, alignment, attention, 100500 depth super-cool recurrent neural network and all that kind superstuff.\n",
    "\n",
    "But even without parallel corpora this system can be good enough (hopefully), in particular for similar languages, e.g. Ukrainian and Russian. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idSYq2GU7uew"
   },
   "source": [
    "### Frament of the Swadesh list for some slavic languages\n",
    "\n",
    "The Swadesh list is a lexicostatistical stuff. It's named after American linguist Morris Swadesh and contains basic lexis. This list are used to define subgroupings of languages, its relatedness.\n",
    "\n",
    "So we can see some kind of word invariance for different Slavic languages.\n",
    "\n",
    "\n",
    "| Russian         | Belorussian              | Ukrainian               | Polish             | Czech                         | Bulgarian            |\n",
    "|-----------------|--------------------------|-------------------------|--------------------|-------------------------------|-----------------------|\n",
    "| женщина         | жанчына, кабета, баба    | жінка                   | kobieta            | žena                          | жена                  |\n",
    "| мужчина         | мужчына                  | чоловік, мужчина        | mężczyzna          | muž                           | мъж                   |\n",
    "| человек         | чалавек                  | людина, чоловік         | człowiek           | člověk                        | човек                 |\n",
    "| ребёнок, дитя   | дзіця, дзіцёнак, немаўля | дитина, дитя            | dziecko            | dítě                          | дете                  |\n",
    "| жена            | жонка                    | дружина, жінка          | żona               | žena, manželka, choť          | съпруга, жена         |\n",
    "| муж             | муж, гаспадар            | чоловiк, муж            | mąż                | muž, manžel, choť             | съпруг, мъж           |\n",
    "| мать, мама      | маці, матка              | мати, матір, неня, мама | matka              | matka, máma, 'стар.' mateř    | майка                 |\n",
    "| отец, тятя      | бацька, тата             | батько, тато, татусь    | ojciec             | otec                          | баща, татко           |\n",
    "| много           | шмат, багата             | багато                  | wiele              | mnoho, hodně                  | много                 |\n",
    "| несколько       | некалькі, колькі         | декілька, кілька        | kilka              | několik, pár, trocha          | няколко               |\n",
    "| другой, иной    | іншы                     | інший                   | inny               | druhý, jiný                   | друг                  |\n",
    "| зверь, животное | жывёла, звер, істота     | тварина, звір           | zwierzę            | zvíře                         | животно               |\n",
    "| рыба            | рыба                     | риба                    | ryba               | ryba                          | риба                  |\n",
    "| птица           | птушка                   | птах, птиця             | ptak               | pták                          | птица                 |\n",
    "| собака, пёс     | сабака                   | собака, пес             | pies               | pes                           | куче, пес             |\n",
    "| вошь            | вош                      | воша                    | wesz               | veš                           | въшка                 |\n",
    "| змея, гад       | змяя                     | змія, гад               | wąż                | had                           | змия                  |\n",
    "| червь, червяк   | чарвяк                   | хробак, черв'як         | robak              | červ                          | червей                |\n",
    "| дерево          | дрэва                    | дерево                  | drzewo             | strom, dřevo                  | дърво                 |\n",
    "| лес             | лес                      | ліс                     | las                | les                           | гора, лес             |\n",
    "| палка           | кій, палка               | палиця                  | patyk, pręt, pałka | hůl, klacek, prut, kůl, pálka | палка, пръчка, бастун |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNM3_fjr7ue2"
   },
   "source": [
    "But the context distribution of these languages demonstrates even more invariance. And we can use this fact for our for our purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLppwa527ue6"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lYBGKAUn7ue_"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Is75c40P022f",
    "outputId": "c6f7833f-b184-45ae-a494-fc51bac5371f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'fastText'...\n",
      "remote: Enumerating objects: 3854, done.\u001b[K\n",
      "remote: Total 3854 (delta 0), reused 0 (delta 0), pack-reused 3854\u001b[K\n",
      "Receiving objects: 100% (3854/3854), 8.22 MiB | 24.55 MiB/s, done.\n",
      "Resolving deltas: 100% (2417/2417), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/fastText.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PyXc4fjJynt9"
   },
   "outputs": [],
   "source": [
    "!cd fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fUCAurJynt9",
    "outputId": "24f983e3-74c4-4c8e-9967-2b7ac2daff39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastText\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n",
      "\r",
      "\u001b[K     |████▊                           | 10kB 22.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 20kB 17.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 30kB 14.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 40kB 13.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 51kB 9.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 61kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 71kB 5.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fastText) (2.6.2)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fastText) (54.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fastText) (1.19.5)\n",
      "Building wheels for collected packages: fastText\n",
      "  Building wheel for fastText (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fastText: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3098974 sha256=08d8a3d855ea896adf012dae410966a10e48f50ecad5810c5c3c96a760394249\n",
      "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
      "Successfully built fastText\n",
      "Installing collected packages: fastText\n",
      "Successfully installed fastText-0.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U-o2OYLxyuEp",
    "outputId": "e22e14f2-b2d6-41e5-e697-4b693bb378bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-05 10:32:46--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1306357571 (1.2G) [binary/octet-stream]\n",
      "Saving to: ‘cc.ru.300.vec.gz’\n",
      "\n",
      "cc.ru.300.vec.gz    100%[===================>]   1.22G  44.6MB/s    in 30s     \n",
      "\n",
      "2021-03-05 10:33:16 (41.2 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_ti8FSajzDSM"
   },
   "outputs": [],
   "source": [
    "!gunzip /content/cc.ru.300.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "okWsPm1J0McX",
    "outputId": "52461cfb-85aa-466d-af82-6a98a8476c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-05 10:34:54--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.uk.300.vec.gz\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1257595219 (1.2G) [binary/octet-stream]\n",
      "Saving to: ‘cc.uk.300.vec.gz’\n",
      "\n",
      "cc.uk.300.vec.gz    100%[===================>]   1.17G  36.9MB/s    in 35s     \n",
      "\n",
      "2021-03-05 10:35:30 (34.4 MB/s) - ‘cc.uk.300.vec.gz’ saved [1257595219/1257595219]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.uk.300.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KdrptLAi0tj1"
   },
   "outputs": [],
   "source": [
    "!gunzip /content/cc.uk.300.vec.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwGoVhRA7ufP"
   },
   "source": [
    "In this notebook we're going to use pretrained word vectors - FastText (original paper - https://arxiv.org/abs/1607.04606).\n",
    "\n",
    "You can download them from the official [website](https://fasttext.cc/docs/en/crawl-vectors.html). We're going to need embeddings for Russian and Ukrainian languages. Please use word2vec-compatible format (.text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "u1JjQv_97ufT"
   },
   "outputs": [],
   "source": [
    "uk_emb = KeyedVectors.load_word2vec_format(\"cc.uk.300.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ffzuept_7ufd"
   },
   "outputs": [],
   "source": [
    "ru_emb = KeyedVectors.load_word2vec_format(\"cc.ru.300.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTkXfT0W7ufk",
    "outputId": "6c2d6bbf-b4c2-4479-ff58-cc33f76f8921"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('август', 1.0),\n",
       " ('июль', 0.9383153915405273),\n",
       " ('сентябрь', 0.9240028858184814),\n",
       " ('июнь', 0.9222575426101685),\n",
       " ('октябрь', 0.9095538854598999),\n",
       " ('ноябрь', 0.8930036425590515),\n",
       " ('апрель', 0.8729087114334106),\n",
       " ('декабрь', 0.8652557730674744),\n",
       " ('март', 0.8545796275138855),\n",
       " ('февраль', 0.8401416540145874)]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([ru_emb[\"август\"]], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vdBA8lcg7ufs",
    "outputId": "93b18612-e660-4c1d-d250-9e70edf8c5f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('серпень', 0.9999999403953552),\n",
       " ('липень', 0.9096440076828003),\n",
       " ('вересень', 0.901697039604187),\n",
       " ('червень', 0.8992519378662109),\n",
       " ('жовтень', 0.8810408711433411),\n",
       " ('листопад', 0.8787633776664734),\n",
       " ('квітень', 0.8592804670333862),\n",
       " ('грудень', 0.8586863279342651),\n",
       " ('травень', 0.8408110737800598),\n",
       " ('лютий', 0.8256431818008423)]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_emb.most_similar([uk_emb[\"серпень\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_yJvcKXO7uf0",
    "outputId": "5ec02d41-1922-42c3-b306-6e5816cdcf72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Stepashka.com', 0.2757962942123413),\n",
       " ('ЖИЗНИВадим', 0.25203436613082886),\n",
       " ('2Дмитрий', 0.25048112869262695),\n",
       " ('2012Дмитрий', 0.24829231202602386),\n",
       " ('Ведущий-Алексей', 0.2443869560956955),\n",
       " ('Недопустимость', 0.24435284733772278),\n",
       " ('2Михаил', 0.23981399834156036),\n",
       " ('лексей', 0.23740756511688232),\n",
       " ('комплексн', 0.23695150017738342),\n",
       " ('персональ', 0.2368222028017044)]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([uk_emb[\"серпень\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNdYAR1q7uf6"
   },
   "source": [
    "Load small dictionaries for correspoinding words pairs as trainset and testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "35d_DAK67uf8"
   },
   "outputs": [],
   "source": [
    "def load_word_pairs(filename):\n",
    "    uk_ru_pairs = []\n",
    "    uk_vectors = []\n",
    "    ru_vectors = []\n",
    "    with open(filename, \"r\") as inpf:\n",
    "        for line in inpf:\n",
    "            uk, ru = line.rstrip().split(\"\\t\")\n",
    "            if uk not in uk_emb or ru not in ru_emb:\n",
    "                continue\n",
    "            uk_ru_pairs.append((uk, ru))\n",
    "            uk_vectors.append(uk_emb[uk])\n",
    "            ru_vectors.append(ru_emb[ru])\n",
    "    return uk_ru_pairs, np.array(uk_vectors), np.array(ru_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wkNL602WHJyO",
    "outputId": "1e838aaf-02f4-4290-9a76-6a39502c512b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-05 10:56:40--  http://tiny.cc/jfgecz\n",
      "Resolving tiny.cc (tiny.cc)... 157.245.113.153\n",
      "Connecting to tiny.cc (tiny.cc)|157.245.113.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://tiny.cc/jfgecz [following]\n",
      "--2021-03-05 10:56:40--  https://tiny.cc/jfgecz\n",
      "Connecting to tiny.cc (tiny.cc)|157.245.113.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.train.txt [following]\n",
      "--2021-03-05 10:56:40--  https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.train.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 59351 (58K) [text/plain]\n",
      "Saving to: ‘ukr_rus.train.txt’\n",
      "\n",
      "ukr_rus.train.txt   100%[===================>]  57.96K  --.-KB/s    in 0.007s  \n",
      "\n",
      "2021-03-05 10:56:41 (8.38 MB/s) - ‘ukr_rus.train.txt’ saved [59351/59351]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O ukr_rus.train.txt http://tiny.cc/jfgecz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uoclU6JcHCcn",
    "outputId": "5fbe28d5-141b-42a0-a3ca-77ffdc583d65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-05 10:56:43--  http://tiny.cc/6zoeez\n",
      "Resolving tiny.cc (tiny.cc)... 157.245.113.153\n",
      "Connecting to tiny.cc (tiny.cc)|157.245.113.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://tiny.cc/6zoeez [following]\n",
      "--2021-03-05 10:56:43--  https://tiny.cc/6zoeez\n",
      "Connecting to tiny.cc (tiny.cc)|157.245.113.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.test.txt [following]\n",
      "--2021-03-05 10:56:43--  https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.test.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12188 (12K) [text/plain]\n",
      "Saving to: ‘ukr_rus.test.txt’\n",
      "\n",
      "ukr_rus.test.txt    100%[===================>]  11.90K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-03-05 10:56:43 (24.4 MB/s) - ‘ukr_rus.test.txt’ saved [12188/12188]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O ukr_rus.test.txt http://tiny.cc/6zoeez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "05BqsdSK7ugD"
   },
   "outputs": [],
   "source": [
    "uk_ru_train, X_train, Y_train = load_word_pairs(\"ukr_rus.train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zQOZw51r7ugL"
   },
   "outputs": [],
   "source": [
    "uk_ru_test, X_test, Y_test = load_word_pairs(\"ukr_rus.test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZBBNvpz7ugQ"
   },
   "source": [
    "## Embedding space mapping (0.3 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_Dhk5gL7ugS"
   },
   "source": [
    "Let $x_i \\in \\mathrm{R}^d$ be the distributed representation of word $i$ in the source language, and $y_i \\in \\mathrm{R}^d$ is the vector representation of its translation. Our purpose is to learn such linear transform $W$ that minimizes euclidian distance between $Wx_i$ and $y_i$ for some subset of word embeddings. Thus we can formulate so-called Procrustes problem:\n",
    "\n",
    "$$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$$\n",
    "or\n",
    "$$W^*= \\arg\\min_W ||WX - Y||_F$$\n",
    "\n",
    "where $||*||_F$ - Frobenius norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acOjDdtL7ugY"
   },
   "source": [
    "$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$ looks like simple multiple linear regression (without intercept fit). So let's code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Lb-KN1be7uga"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# mapping = ...\n",
    "# -------\n",
    "mapping = LinearRegression(fit_intercept=False).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7tqJwoY7ugf"
   },
   "source": [
    "Let's take a look at neigbours of the vector of word _\"серпень\"_ (_\"август\"_ in Russian) after linear transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31SrFSbn7ugi",
    "outputId": "584fcbd8-d3fb-42bc-ffdd-9ca7eb34768c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('апрель', 0.8531432747840881),\n",
       " ('июнь', 0.8402522802352905),\n",
       " ('март', 0.8385884165763855),\n",
       " ('сентябрь', 0.8331484794616699),\n",
       " ('февраль', 0.8311208486557007),\n",
       " ('октябрь', 0.8278019428253174),\n",
       " ('ноябрь', 0.8243728280067444),\n",
       " ('июль', 0.8229618072509766),\n",
       " ('август', 0.8112280368804932),\n",
       " ('январь', 0.8022986650466919)]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
    "ru_emb.most_similar(august)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okSkjk597ugo"
   },
   "source": [
    "We can see that neighbourhood of this embedding cosists of different months, but right variant is on the ninth place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2uY6Y9B7ugt"
   },
   "source": [
    "As quality measure we will use precision top-1, top-5 and top-10 (for each transformed Ukrainian embedding we count how many right target pairs are found in top N nearest neighbours in Russian embedding space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zptuho8LAfIE"
   },
   "outputs": [],
   "source": [
    "def precision(pairs, mapped_vectors, topn=1):\n",
    "    \"\"\"\n",
    "    :args:\n",
    "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
    "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
    "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
    "    :returns:\n",
    "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(pairs) == len(mapped_vectors)\n",
    "    num_matches = 0\n",
    "\n",
    "    translations = [ru_emb.most_similar(mapped_vectors[i].reshape(-1, 1).T, topn=topn) for i in range(len(mapped_vectors))]\n",
    "\n",
    "    neighbours = []\n",
    "    for i in range(len(translations)):\n",
    "        word_neighbours, _ = zip(*translations[i])\n",
    "        neighbours.append(word_neighbours)\n",
    "\n",
    "    for i, (_, ru) in enumerate(pairs):\n",
    "        # YOUR CODE HERE\n",
    "        num_matches += int(ru in neighbours[i])\n",
    "    precision_val = num_matches / len(pairs)\n",
    "    return precision_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "duhj9hpv7ugy"
   },
   "outputs": [],
   "source": [
    "assert precision([(\"серпень\", \"август\")], august, topn=5) == 0.0\n",
    "assert precision([(\"серпень\", \"август\")], august, topn=9) == 1.0\n",
    "assert precision([(\"серпень\", \"август\")], august, topn=10) == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-iyd5gP7ug5"
   },
   "outputs": [],
   "source": [
    "assert precision(uk_ru_test, X_test) == 0.0\n",
    "assert precision(uk_ru_test, Y_test) == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-ssEJ3x7uhA"
   },
   "outputs": [],
   "source": [
    "precision_top1 = precision(uk_ru_test, mapping.predict(X_test), 1)\n",
    "precision_top5 = precision(uk_ru_test, mapping.predict(X_test), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7K-hy7a6Ksn2",
    "outputId": "d67f16d6-d64d-4aaf-afe7-1e6cb23e3fc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.628498727735369\n",
      "0.7913486005089059\n"
     ]
    }
   ],
   "source": [
    "print(precision_top1)\n",
    "print(precision_top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hf6Ou8bx7uhH"
   },
   "source": [
    "## Making it better (orthogonal Procrustean problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oLs-drN7uhK"
   },
   "source": [
    "It can be shown (see original paper) that a self-consistent linear mapping between semantic spaces should be orthogonal. \n",
    "We can restrict transform $W$ to be orthogonal. Then we will solve next problem:\n",
    "\n",
    "$$W^*= \\arg\\min_W ||WX - Y||_F \\text{, where: } W^TW = I$$\n",
    "\n",
    "$$I \\text{- identity matrix}$$\n",
    "\n",
    "Instead of making yet another regression problem we can find optimal orthogonal transformation using singular value decomposition. It turns out that optimal transformation $W^*$ can be expressed via SVD components:\n",
    "$$X^TY=U\\Sigma V^T\\text{, singular value decompostion}$$\n",
    "$$W^*=UV^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_KSaRJFGMFiJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "DdFQ7qti7uhL"
   },
   "outputs": [],
   "source": [
    "def learn_transform(X_train, Y_train):\n",
    "    \"\"\" \n",
    "    :returns: W* : float matrix[emb_dim x emb_dim] as defined in formulae above\n",
    "    \"\"\"\n",
    "    # YOUR CODE GOES HERE\n",
    "    # compute orthogonal embedding space mapping\n",
    "    # mapping = ...\n",
    "    U, S, V = np.linalg.svd(X_train.T.dot(Y_train))\n",
    "    mapping = U.dot(V)\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7X7QfYDd7uhQ"
   },
   "outputs": [],
   "source": [
    "W = learn_transform(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVOFYYa37uhX",
    "outputId": "04840e86-40ca-4337-fe04-8234497a8c30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('апрель', 0.8245131969451904),\n",
       " ('июнь', 0.805662989616394),\n",
       " ('сентябрь', 0.8055761456489563),\n",
       " ('март', 0.8032935261726379),\n",
       " ('октябрь', 0.7987102270126343),\n",
       " ('июль', 0.7946797013282776),\n",
       " ('ноябрь', 0.7939636707305908),\n",
       " ('август', 0.7938188910484314),\n",
       " ('февраль', 0.7923861145973206),\n",
       " ('декабрь', 0.7715375423431396)]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([np.matmul(uk_emb[\"серпень\"], W)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r297sYP37uhb",
    "outputId": "0a268fb4-88fa-4d23-d67b-921887268773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6437659033078881\n",
      "0.7989821882951654\n"
     ]
    }
   ],
   "source": [
    "print(precision(uk_ru_test, np.matmul(X_test, W)))\n",
    "print(precision(uk_ru_test, np.matmul(X_test, W), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvUZ72U5AfJg"
   },
   "source": [
    "## Unsupervised embedding-based MT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLyuVfHBLrJn"
   },
   "source": [
    "Now, let's build our word embeddings-based translator!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPAURW1CMuP7"
   },
   "source": [
    "Firstly, download OPUS Tatoeba corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F80kUKzQMsDu",
    "outputId": "76eed00f-1b60-4fae-df7b-ab76eded736a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-05 10:57:57--  https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/mono/uk.txt.gz\n",
      "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
      "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1819128 (1.7M) [application/gzip]\n",
      "Saving to: ‘uk.txt.gz’\n",
      "\n",
      "uk.txt.gz           100%[===================>]   1.73M  1.51MB/s    in 1.2s    \n",
      "\n",
      "2021-03-05 10:58:00 (1.51 MB/s) - ‘uk.txt.gz’ saved [1819128/1819128]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/mono/uk.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "0CGFZoxCUVf1"
   },
   "outputs": [],
   "source": [
    "!gzip -d ./uk.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "2MV3VvoVUX5U"
   },
   "outputs": [],
   "source": [
    "with open('./uk.txt', 'r') as f:\n",
    "    uk_corpus = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "tU7nPVf0UhbI"
   },
   "outputs": [],
   "source": [
    "# To save your time and CPU, feel free to use first 1000 sentences of the corpus\n",
    "uk_corpus = uk_corpus[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "FLN8dBOXAfJ1"
   },
   "outputs": [],
   "source": [
    "# Any necessary preprocessing if needed\n",
    "# YOUR CODE HERE\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "preprocess = lambda text: ' '.join(tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "FGksC7l_NMi9"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    \"\"\"\n",
    "    :args:\n",
    "        sentence - sentence in Ukrainian (str)\n",
    "    :returns:\n",
    "        translation - sentence in Russian (str)\n",
    "\n",
    "    * find ukrainian embedding for each word in sentence\n",
    "    * transform ukrainian embedding vector\n",
    "    * find nearest russian word and replace\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE GOES HERE\n",
    "    splitted_text_uk = preprocess(sentence).split(\" \")\n",
    "    translated = []\n",
    "    for uk_word in splitted_text_uk:\n",
    "        try:\n",
    "          similar_word = ru_emb.most_similar([np.matmul(uk_emb[uk_word], W)], topn=1)[0][0]\n",
    "          translated.append(similar_word)\n",
    "        except KeyError:\n",
    "          translated.append(uk_word)\n",
    "    return \" \".join(translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "4hbbMy-tNxlf"
   },
   "outputs": [],
   "source": [
    "assert translate(\".\") == \".\"\n",
    "assert translate(\"1 , 3\") == \"1 , 3\"\n",
    "assert translate(\"кіт зловив мишу\") == \"кот поймал мышку\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ia6I2ce7O_HI"
   },
   "source": [
    "Now you can play with your model and try to get as accurate translations as possible. **Note**: one big issue is out-of-vocabulary words. Try to think of various ways of handling it (you can start with translating each of them to a special **UNK** token and then move to more sophisticated approaches). Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ap1W7ZCeOAVU",
    "outputId": "a9e10c39-4d7b-4cbf-a34f-6515972d97bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukraine sentence: \n",
      "Я вже закінчу коледж, коли ви вернетеся з Америки.\n",
      "\n",
      "Russian translation: \n",
      "мной уже закончу колледж , когда мы прибежишь со америки .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Місто бомбардували ворожі літаки.\n",
      "\n",
      "Russian translation: \n",
      "город бомбили враждебные самолеты .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Можливо, я антисоціальний, але це не означає, що я не спілкуюся з людьми.\n",
      "\n",
      "Russian translation: \n",
      "возможно , мной антисоциальный , конечно это не означает , что мной не общаюсь со людьми .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Цього ранку випала роса.\n",
      "\n",
      "Russian translation: \n",
      "этого утра выпала роса .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Біда не приходить одна.\n",
      "\n",
      "Russian translation: \n",
      "беда не приходит одна .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Подивися на той дим.\n",
      "\n",
      "Russian translation: \n",
      "посмотри по тот дым .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Я замовив два гамбургера.\n",
      "\n",
      "Russian translation: \n",
      "мной заказал два гамбургера .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Я не хотів нікого образити.\n",
      "\n",
      "Russian translation: \n",
      "мной не хотел никого обидеть .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Гора вкрита снігом.\n",
      "\n",
      "Russian translation: \n",
      "гора покрыта снегом .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "На фотографії в дівчини корона не з золота, а з квітів.\n",
      "\n",
      "Russian translation: \n",
      "по фотографии во девушки корона не со золота , а со цветов .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "У мене є мрія.\n",
      "\n",
      "Russian translation: \n",
      "во меня То мечта .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Я приїхав у Японію з Китаю.\n",
      "\n",
      "Russian translation: \n",
      "мной приехал во японію со китая .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "На півночі знаходиться Шотландія; на півдні — Англія; на заході — Уельс; і ще далі на заході — Північна Ірландія.\n",
      "\n",
      "Russian translation: \n",
      "по север находится шотландія ; по юге — англия ; по востоке — англо-саксонский ; и ещe дальше по востоке — северная шотландия .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Його рідна країна — Німеччина.\n",
      "\n",
      "Russian translation: \n",
      "его родная страна — германия .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Берн — столиця Швейцарії.\n",
      "\n",
      "Russian translation: \n",
      "Уотертаун — столица ирландии .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Він чекав на нього до десятої години.\n",
      "\n",
      "Russian translation: \n",
      "он ждал по него к десятой часа .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Ти можеш взяти цю книгу даром.\n",
      "\n",
      "Russian translation: \n",
      "ты можешь взять ту книгу даром .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Цей роман написав відомий американський письменник.\n",
      "\n",
      "Russian translation: \n",
      "этот роман сочинил известный американский писатель .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Забронюйте, будьте ласкаві, кімнату біля міжнародного аеропорту в Торонто.\n",
      "\n",
      "Russian translation: \n",
      "забронировать , будте ласковые , комнату возле международного аэропорта во торонто .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Він знає, що ти його кохаєш?\n",
      "\n",
      "Russian translation: \n",
      "он знает , что ты его влюбится ?\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Я знаю, що ти багатий.\n",
      "\n",
      "Russian translation: \n",
      "мной знаю , что ты богатый .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Ті, хто все забувають, щасливі.\n",
      "\n",
      "Russian translation: \n",
      "те , кто всё забывают , счастливые .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "В цій річці небезпечно плавати.\n",
      "\n",
      "Russian translation: \n",
      "во этой реке опасно плавать .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Прийшов, побачив, переміг.\n",
      "\n",
      "Russian translation: \n",
      "пришел , увидел , победил .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Я ходжу до школи пішки.\n",
      "\n",
      "Russian translation: \n",
      "мной хожу к школы пешком .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Не твоя справа!\n",
      "\n",
      "Russian translation: \n",
      "не моя дело !\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Не забудь квиток.\n",
      "\n",
      "Russian translation: \n",
      "не забудь билет .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Хто він?\n",
      "\n",
      "Russian translation: \n",
      "кто он ?\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Ви будете чай чи каву?\n",
      "\n",
      "Russian translation: \n",
      "мы будете чай ли кофе ?\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Він не піде на пікнік, як і я.\n",
      "\n",
      "Russian translation: \n",
      "он не пойдет по пикник , как и мной .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Коли Ви народилися?\n",
      "\n",
      "Russian translation: \n",
      "когда мы родились ?\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Це моя улюблена пісня.\n",
      "\n",
      "Russian translation: \n",
      "это моя любимая песня .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Ми майже сім’я.\n",
      "\n",
      "Russian translation: \n",
      "мы почти семь со мной .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Який гарний сьогодні місяць!\n",
      "\n",
      "Russian translation: \n",
      "который красивый сегодня месяц !\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Я проти будь-яких війн.\n",
      "\n",
      "Russian translation: \n",
      "мной против каких-либо войны .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Поверхня повітряної кулі — неевклідовий простір, тому для неї не виконуються правила евклідової геометрії.\n",
      "\n",
      "Russian translation: \n",
      "поверхность воздушной шары — неевклідовий пространство , потому для неё не выполняются правила симметрической геометрии .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Кажуть, що американці вважають кількість грошей, яку заробляє людина, мірилом його уміння.\n",
      "\n",
      "Russian translation: \n",
      "дескать , что американцы считают количество денег , какую зарабатывает женщина , мерилом его умение .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Можна я примірю це плаття?\n",
      "\n",
      "Russian translation: \n",
      "можно мной примірю это платье ?\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Якщо буде гарна погода, ми доберемося туди завтра.\n",
      "\n",
      "Russian translation: \n",
      "если будет красивая погода , мы доберёмся туда завтра .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Це був злий заєць.\n",
      "\n",
      "Russian translation: \n",
      "это был злой заяц .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Один, два, три, чотири, п'ять, шість, сім, вісім, дев'ять, десять.\n",
      "\n",
      "Russian translation: \n",
      "один , два , три , четыре , п'ять , восемь , семь , восемь , дев'ять , десять .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Хто в любові не знається, той горя не знає.\n",
      "\n",
      "Russian translation: \n",
      "кто во любви не знает , тот горя не знает .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Його мати хвилюється за нього.\n",
      "\n",
      "Russian translation: \n",
      "его иметь волнуется за него .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Я поважаю тих, хто старається з усіх сил.\n",
      "\n",
      "Russian translation: \n",
      "мной уважаю тех , кто старается со всех сил .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Їхня дружба переросла у глибоке кохання.\n",
      "\n",
      "Russian translation: \n",
      "эта дружба переросла во глубокое любовь .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Кейт п’є багато молока кожен день.\n",
      "\n",
      "Russian translation: \n",
      "джастин аш со То много молока каждый день .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Він злодій.\n",
      "\n",
      "Russian translation: \n",
      "он вор .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Шумового забруднення можна було б позбігнути тільки якщо б люди були більш чутливими до навколишнього середовища.\n",
      "\n",
      "Russian translation: \n",
      "шумового загрязнение можно было бы позбігнути только если бы люди были более чувствительны к окружающей среды .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Чай з лимоном, будьте ласкаві.\n",
      "\n",
      "Russian translation: \n",
      "чай со лимоном , будте ласковые .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Не плутай бажання з коханням.\n",
      "\n",
      "Russian translation: \n",
      "не путать желание со влюбленностью .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Я би з задоволенням написав сотні речень в Tatoeb’і, але в мене є справи.\n",
      "\n",
      "Russian translation: \n",
      "мной бы со удовольствием сочинил сотни сложноподчинённые во tatoeb со и , конечно во меня То дела .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Дайте мені філіжанку кави.\n",
      "\n",
      "Russian translation: \n",
      "дайте мне чашечку кофе .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Але ж ти ніколи мені про це не розповідала!\n",
      "\n",
      "Russian translation: \n",
      "конечно же ты никогда мне о это не рассказывала !\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "У тебе будуть проблеми, якщо твої батьки довідаються.\n",
      "\n",
      "Russian translation: \n",
      "во тебя будут проблемы , если твои родители узнают .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Запах троянд наповнив кімнату.\n",
      "\n",
      "Russian translation: \n",
      "запах роз наполнил комнату .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Як у тебе справи?\n",
      "\n",
      "Russian translation: \n",
      "как во тебя дела ?\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Це мої штани.\n",
      "\n",
      "Russian translation: \n",
      "это мои штаны .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Ні, дякую.\n",
      "\n",
      "Russian translation: \n",
      "ни , спасибо .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Я не розумію, чому Німеччина перемогла на Євробаченні.\n",
      "\n",
      "Russian translation: \n",
      "мной не понимаю , почему германия победила по Евровиденье .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Добрий вечір.\n",
      "\n",
      "Russian translation: \n",
      "хороший вечер .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "З юбілеєм Олексія Дударева привітав Президент Білорусі Олександр Лукашенко.\n",
      "\n",
      "Russian translation: \n",
      "со юбілеєм олексія дударева поприветствовал президент беларуссии борис путина. .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Чумацький шлях — широкий пояс із далеких зірок, кожна зірка — сонце, таке як наше.\n",
      "\n",
      "Russian translation: \n",
      "привольный путь — широкий пояс со далеких звёзд , каждая звезда — солнце , такое как наше .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Незвичайно бачити рок-зірок з краваткою!\n",
      "\n",
      "Russian translation: \n",
      "необычайно видеть рок-звёзд со галстук !\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Усе печиво у формі зірок.\n",
      "\n",
      "Russian translation: \n",
      "всё печенье во форме звёзд .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Що мені вдягнути — штани чи спідницю?\n",
      "\n",
      "Russian translation: \n",
      "что мне одеть — штаны ли юбку ?\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Гартман Вітвер — відомий львівський скульптор.\n",
      "\n",
      "Russian translation: \n",
      "гартман вітвер — известный московский скульптор .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "То був злий кролик.\n",
      "\n",
      "Russian translation: \n",
      "то был злой кролик .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Можеш взяти будь-який, що тобі до сподоби.\n",
      "\n",
      "Russian translation: \n",
      "можешь взять любой , что тебе к отвратиться .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Звичайно я піду.\n",
      "\n",
      "Russian translation: \n",
      "конечно мной пойду .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Шовкопряди прядуть кокони.\n",
      "\n",
      "Russian translation: \n",
      "шелковичные прядут коконы .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Що б ти зробила, якщо б у тебе було, скажім, десять тисяч доларів?\n",
      "\n",
      "Russian translation: \n",
      "что бы ты сделала , если бы во тебя было , замечу , десять тысяч долларов ?\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Він думає, що він хтось, а насправді він ніхто.\n",
      "\n",
      "Russian translation: \n",
      "он думает , что он кто-то , а действительно он никто .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Вона дуже пишається своєю колекцією марок.\n",
      "\n",
      "Russian translation: \n",
      "она очень гордится своею коллекцией марок .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Він дуже простий...\n",
      "\n",
      "Russian translation: \n",
      "он очень простой ...\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Яка ти добра!\n",
      "\n",
      "Russian translation: \n",
      "она ты добра !\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Як я за тобою скучив!\n",
      "\n",
      "Russian translation: \n",
      "как мной за тобой соскучился !\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Це все, що я знаю.\n",
      "\n",
      "Russian translation: \n",
      "это всё , что мной знаю .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Ти ведеш щоденник?\n",
      "\n",
      "Russian translation: \n",
      "ты ведёшь дневник ?\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Тобі вирішувати.\n",
      "\n",
      "Russian translation: \n",
      "тебе решать .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Це пошта, а то — банк.\n",
      "\n",
      "Russian translation: \n",
      "это почта , а то — банк .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Це все, що я хочу зробити.\n",
      "\n",
      "Russian translation: \n",
      "это всё , что мной хочу сделать .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Я вперше дивлюся такий страшний фільм.\n",
      "\n",
      "Russian translation: \n",
      "мной впервые смотрю такой страшный фильм .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Ця пісня нагадує мені про дім.\n",
      "\n",
      "Russian translation: \n",
      "та песня напоминает мне о дом .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Хіросі тут?\n",
      "\n",
      "Russian translation: \n",
      "хіросі здесь ?\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Мене звуть Джек.\n",
      "\n",
      "Russian translation: \n",
      "меня зовут джэк .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Як людина живе, так вона і помре.\n",
      "\n",
      "Russian translation: \n",
      "как женщина живет , так она и умрет .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Я тут уже дві години.\n",
      "\n",
      "Russian translation: \n",
      "мной здесь уже две часа .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Мені треба вибачитись перед Ен.\n",
      "\n",
      "Russian translation: \n",
      "мне надо извиниться перед ен .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Сьогодні я бачив шпака.\n",
      "\n",
      "Russian translation: \n",
      "сегодня мной видел скворца .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "«Скільки коштує ця носова хусточка?» — «Дев'яносто п'ять центів».\n",
      "\n",
      "Russian translation: \n",
      "« сколько стоить та носовая косыночка ? » — « дев'яносто п'ять центов » .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Ранені ведмеді, як правило, дуже небезпечні.\n",
      "\n",
      "Russian translation: \n",
      "раненные медведи , как правило , очень опасные .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Він швидко втомлюється.\n",
      "\n",
      "Russian translation: \n",
      "он быстро устает .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Усі готові.\n",
      "\n",
      "Russian translation: \n",
      "все готовы .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Він скучає по своїй сім'ї.\n",
      "\n",
      "Russian translation: \n",
      "он скучает по своей сім'ї .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "«Дякую», — «На здоров'я».\n",
      "\n",
      "Russian translation: \n",
      "« спасибо » , — « по здоров'я » .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Я ще не знаю своєї адреси, я певний час буду жити в подруги.\n",
      "\n",
      "Russian translation: \n",
      "мной ещe не знаю своего адреса , мной определенный момент буду жить во подруги .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Амазонка— друга по довжині ріка в світі після Ніла.\n",
      "\n",
      "Russian translation: \n",
      "амазонка — вторая по длине река во мире после трепещущая .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "А якщо побачиш Тома, передай йому від мене вітання.\n",
      "\n",
      "Russian translation: \n",
      "а если увидишь тома , передай ему от меня поздравления .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Закрий за собою двері.\n",
      "\n",
      "Russian translation: \n",
      "закрой за собой дверь .\n",
      "\n",
      "\n",
      "Ukraine sentence: \n",
      "Тримай при собі словник.\n",
      "\n",
      "Russian translation: \n",
      "держи при себе словарь .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in uk_corpus[::10]:\n",
    "    print(\"Ukraine sentence: \")\n",
    "    print(sent)\n",
    "    print(\"Russian translation: \")\n",
    "    print(translate(sent))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsFptwjwlwTB"
   },
   "source": [
    "Great! \n",
    "See second notebook for the Neural Machine Translation assignment."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Lab1_part1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
